# task01

## lexer
- for tokenizer it currently uses my parser combinators from [rampy](https://github.com/adaxiik/rampy/blob/main/src/parser_combinators.py)

## parsing
- we currently do [pratt parsing](https://en.wikipedia.org/wiki/Operator-precedence_parser#Pratt_parsing)

## eval
- tree walking
